{"id":"mcpIndexer-104","title":"Switch to code-specific embedding model (jina-embeddings-v2-base-code)","description":"**Goal**: Replace the general-purpose embedding model (all-MiniLM-L6-v2) with an optimized model for semantic code search.\n\n**What we accomplished**: Benchmarked 5 different embedding models and selected multi-qa-mpnet-base-dot-v1 based on performance:\n\nBenchmark Results:\n- ✓ multi-qa-mpnet-base-dot-v1: 100% accuracy, 0.07s indexing, 11ms queries (SELECTED)\n- all-MiniLM-L6-v2 (old): 100% accuracy, 0.15s indexing, 27ms queries\n- msmarco-bert-base-dot-v5: 100% accuracy, 0.15s indexing, 30ms queries\n- all-mpnet-base-v2: 100% accuracy, 1.42s indexing, 287ms queries\n- ✗ jina-embeddings-v2-base-code: 80% accuracy, 0.40s indexing, 345ms queries (rejected)\n\n**Impact**: \n- 2x faster indexing (0.15s → 0.07s)\n- 2.4x faster queries (27ms → 11ms)\n- Maintains 100% accuracy on code search\n\n**Implementation**:\n✓ Update DEFAULT_MODEL in embeddings.py\n✓ Add MCP_INDEXER_MODEL environment variable\n✓ Create benchmark_models.py for testing\n✓ Document model selection rationale\n✓ Add configuration option for model choice\n✓ Test with multiple models","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-10-27T18:13:28.385434-05:00","updated_at":"2025-10-27T18:38:37.020025-05:00","closed_at":"2025-10-27T18:30:57.20244-05:00"}
