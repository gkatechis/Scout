{"id":"mcpIndexer-105","title":"Add GPU acceleration support for embeddings","description":"**Goal**: Enable GPU acceleration for embedding generation to dramatically improve indexing speed.\n\n**What we're accomplishing**: Sentence-transformers supports CUDA/GPU acceleration which provides 10-50x speedup:\n- CPU: 170-750 queries/sec\n- GPU: 4,000-18,000 queries/sec\n\n**Impact**: Indexing large repositories becomes 10-50x faster. A repo that takes 10 minutes could index in 12-60 seconds.\n\n**Implementation**:\n- Auto-detect GPU availability (torch.cuda.is_available())\n- Add device parameter to SentenceTransformer initialization\n- Add configuration option to force CPU/GPU\n- Update documentation with GPU setup instructions\n- Gracefully fallback to CPU if GPU unavailable","status":"in_progress","priority":1,"issue_type":"feature","created_at":"2025-10-27T18:13:33.834705-05:00","updated_at":"2025-10-27T20:02:20.410013-05:00"}
